{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "976a2cc1-bcc8-4159-a80d-510e08b8520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0359b5cf-83c5-4121-ad3b-8213ebd45204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1bad586-ee86-4bba-9385-e02be4d9a885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam_ham_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8dd826b1-6bfa-4681-b52b-fd09c7a94208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "label         0\n",
       "text          0\n",
       "label_num     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for NaN entries\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88aaf6fe-4e3b-4a75-b368-d69339346204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "3474    False\n",
       "3452    False\n",
       "3451    False\n",
       "3450    False\n",
       "        ...  \n",
       "1722    False\n",
       "1721    False\n",
       "1720    False\n",
       "1719    False\n",
       "5170    False\n",
       "Length: 5171, dtype: bool"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970978d9-fbd8-4c6a-a1a3-c1f901238b47",
   "metadata": {},
   "source": [
    "The given dataset is clean and there is no need for Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40547b1-ebb7-4e38-9ad3-9ecf77e58812",
   "metadata": {},
   "source": [
    "# Implementing the BOW Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7054f3b-5013-41c4-86d2-0cbdd927fa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kanth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "\n",
    "all_stop_words = set(stopwords.words('english'))\n",
    "all_stop_words.remove('not')\n",
    "\n",
    "for i in range (len(df)):\n",
    "    text = df['text'][i].lower().translate(str.maketrans('','', string.punctuation)).split()\n",
    "    text = [ps.stem(word) for word in text if word not in all_stop_words]\n",
    "    text = ' '.join(text)\n",
    "    corpus.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f273041-6697-40c3-b7d4-af1b708f2a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42500"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the BOW Model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features= 42500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = df['label_num']\n",
    "\n",
    "len(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce73fcd8-d490-46a0-b440-447471eddd7d",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35b3e087-a594-4411-b7d4-63667d3b6cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b1a0fdb-9e07-4a89-9efa-11e1c451796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "def model_score(y_true,y_pred):\n",
    "    acc_scor = accuracy_score(y_true, y_pred)\n",
    "    prec_scor = precision_score(y_true, y_pred)\n",
    "    recall_scor = recall_score(y_true, y_pred)\n",
    "    f1_scor = f1_score(y_true, y_pred)\n",
    "    overall_avg_score = (acc_scor + prec_scor + recall_scor + f1_scor) / 4\n",
    "\n",
    "    print(f'Model accuracy score: {acc_scor}')\n",
    "    print(f'Model precision score: {prec_scor}')\n",
    "    print(f'Model recall score: {recall_scor}')\n",
    "    print(f'Model f1 score: {f1_scor}')\n",
    "    print(f'Average overall score performance: {overall_avg_score}')\n",
    "\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68256fea-9484-4b39-9105-fff835f3a3e5",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd9b222a-e211-4eaf-a7af-26bc2e72b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "cl_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "cl_rf.fit(X_train, y_train)\n",
    "y_pred = cl_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b432d1c8-c35f-4de4-b11a-c85b1718efe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score: 0.9719806763285024\n",
      "Model precision score: 0.9506578947368421\n",
      "Model recall score: 0.9537953795379538\n",
      "Model f1 score: 0.9522240527182867\n",
      "Average overall score performance: 0.9571645008303963\n",
      "[[717  15]\n",
      " [ 14 289]]\n"
     ]
    }
   ],
   "source": [
    "#Model Performance\n",
    "\n",
    "model_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
